#!/bin/bash	# This is just to enable automatic syntax highlighting this isn't really a bash script
#
#	This file contains the settings to control how the GPU acceleration search is carried out
#	#'s Comment out lines, blank lines are ignored
#
#	None of the values in this file are "essential" anything can be commented out and the application
#	will determine an appropriate default, so you wont break it by removing something.
#	However you can make things go slow or bad by changing values so be careful, you can always get the defaults off the GIT repo
#
#	There are some comments, but for most configurations there is to much information to really go into detail
#	If you have any questions pleas e-mail Chris Laidler:  chris.laidler+presto@gmail.com
#	I will happily answer any queries you may have
#
#	There are two formats to the parameters.
#	The first is simply a line with the parameter name (case sensitive) followed by white space followed by the value ie:

DUMMY_PARAMETER	DUMMY_VALUE

#	I have included some description of these in commented blocks above the parameter, the layout is something like:

# DUMMY_PARAMETER:		# This is the name of the parameter (excluding colon), Below is a list of the possible values, these could be text or numeric
#	VAL_01			# The value is "VAL_01" and here is a comment describing what it dose
# D	VAL_02			# The D on the far left shows that "VAL_02" is the default option
#	DUMMY_VALUE		# This is the value I set in the example above
DUMMY_PARAMETER	DUMMY_VALUE	# This uncommented line setts the actual value of the parameter, this line can be commented out

#	The second way a parameter is set is simply with the parameter name. These "flags" can be disable by simply commenting them out or they can be explicitly turned off by following them with "0" or "off"
#	Below is an example of these:
DUMMY_FLAG_ONE			# This enables the flag "DUMMY_FLAG_ONE"
DUMMY_FLAG_TWO off		# This will disable the flag "DUMMY_FLAG_TWO", you can just comment it out as well

#	These flags often correspond to one of the bit flags used in "cuda_accel.h" used to configure the GPU search


########################### General ###########################


R_RESOLUTION	2

Z_RESOLUTIOM	2

#FLAG_Z_SPLIT			# Force splitting of the in-memory plane - Not advisable

RESULTS_RING	3


########################### Memory ############################

# Interleaving
# INTERLEAVE:
# D	ROW			# Interleave steps row by row
#	PLN			# Interleave steps row by plane
INTERLEAVE		ROW


############################ Kernel ############################

# Response function length
# RESPONSE:
# D	STD			# Standard low accuracy method of choosing the half-width
#	HIGH    		# Choose larger half-width for higher accuracy of value of z close to 0 - This may make the search a tad more sensitive
#	MAX     		# Choose largest possible response function width - not a good idea
RESPONSE		STD


# Use the largest possible response function width - Not really a good idea
#FLAG_KER_MAX


# Centre and align the usable part of the planes (this is on by default, it can be disabled with CENTER_RESPONSE 0 or CENTER_RESPONSE off )
#CENTER_RESPONSE


# RESPONSE_PRECISION:
#	SINGLE  		# Calculate kernel response values using single precision
# D	DOUBLE  		# Calculate kernel response values using double precision (generally A good idea)
RESPONSE_PRECISION 	DOUBLE


# KER_FFT_PRECISION
# D	SINGLE  		# FFT the kernel elements using double precision (final results still stored as floats)
#	DOUBLE  		# FFT the kernel elements using double precision (final results still stored as floats)
KER_FFT_PRECISION 	SINGLE


############################# Input ############################

# Normalise input in the CPU or the GPU
# INP_NORM:
# 	CPU     		# Do the input Normalisation on the CPU - This is usually the best option, the task is short enough that the CPU may as well do it (unless Z-Max is very small  ( < ~10 )
#	GPU     		# Do the input Normalisation on the GPU using an in-place Shared Memory sort
#	GPU_SM     		# DEBUG: Do the input Normalisation on the GPU using an in-place Shared Memory sort
#	GPU_SM_MIN     		# DEBUG: Do the input Normalisation on the GPU using an in-place Shared Memory sort - Minimise SM use
#	GPU_OS			# DEBUG: Do the input Normalisation on the GPU using a custom novel order statistic algorithm
# D	AA      		# Automatically chose, This will usually use the CPU but may use the GPU if z-max is small
INP_NORM		AA


# ZBOUND_NORM:
# This marks a boundary, if the search z-max exceeds this value the CPU will be used for input normalisation. I find this should generally be low, the CPU is better at normalisation.
# Any result of ZBOUND_NORM may be over ridden by ZBOUND_INP_FFT
# iff z-max is equal or exceeds ZBOUND_NORM, the CPU will be used for input normalisation, This will will override any value of INP_NORM.
# if z-max is less than ZBOUND_NORM, GPU normalisation will be used, This will will override any value of INP_NORM.
# if ZBOUND_NORM is commented out or set to -1 INP_NORM will be used.
#ZBOUND_NORM		-1


# FFT input in the CPU or the GPU
# INP_FFT:
#	CPU     		# Do the input FFT's on the CPU
# D	GPU     		# Do the input FFT's on the GPU - I generally find this a bit faster
# 	AA			# Automatically chose, for the moment this will use the GPU
INP_FFT			AA


# ZBOUND_INP_FFT:
# This marks a boundary, if the search z-max exceeds this value the CPU will be used for input FFT ( and thus input normalisation).
# iff z-max is equal or exceeds ZBOUND_INP_FFT it use the CPU and it will override INP_FFT, INP_NORM and ZBOUND_NORM.
# if z-max is less than it, CPU FFT's will be used. This will will override any value of INP_FFT and no charge will be made to input normalisation.
# if ZBOUND_INP_FFT is commented out or set to -1 INP_NORM, ZBOUND_NORM and INP_FFT will be used.
#ZBOUND_FFT		-1


# This is the size of buffers to use in the median selection algorithm used by the CUDA input normalisation kernel this should be one of: 128, 256, 512, 1024, 2048, 4096, 8192
# Don't fiddle with this
# cuMedianBuffSz:
# D	0			# Let the application decide
#	128
#	256
#	512
#	1024
#	2048
#	4096
#	8192
cuMedianBuffSz		0


########################### Convolve ###########################

# Which type of multiplication to do.
# MUL_KER:
#	00      		# DEBUG NB: This is just a dummy kernel and will give incorrect values! (it is close to optimal calculations)
#	11
#	21
#	22
#	23
#	31
#	CB      		# This does the multiplication using CUFFT callbacks, in my testing this is very slow, like 7 times slower (FFT only)!
# D	AA      		# Automatically chose, This may well select different kernel per stack
MUL_KER			AA


# [Deprecated]  Use texture memory in the multiplication kernel
#MUL_TEXTURE


# The number of horizontal "slices" to break the Sum & Search kernel into
# MUL_SLICES:
# D	0       		# Let the application decide
#	int     		# A number generally less than 7 and odd are "better"
MUL_SLICES		0


# The number of values to buffer in the multiplication kernel (this increases register use)
# MUL_CHUNK:
# D	0       		# Let the application decide
#	int     		# A number <= 8
MUL_CHUNK		0


# How to do convolution
#CONVOLVE:
# D	SEP     		# Do the multiplication and iFFT "separately"   ie all multiplications followed by all iFFT's
#	CONT    		# Do the multiplication and iFFT "together"     ie multiply and iFFT each stack one after the other
#CONVOLVE		SEP


# Which order to process stacks
# STACK:
# D	DOWN    		# Largest to smallest
#	UP      		# Smallest to largest
#STACK			DOWN


############################ FFT ###############################

# CUFFT_PLAN_PLN:
#	SEPARATE		Use separate CUFFT plans for each batch
# D	SINGLE			Use one plan for all batches on a device - Saves a bit of memory and generally doesn't slow things down much
#CUFFT_PLAN_PLN 		SINGLE

# CUFFT_PLAN_INP:
# Same as above, but generally always a good idea to be SEPARATE, which is the default
#
# D	SEPARATE		Use separate CUFFT plans for each batch
#	SINGLE			Use one plan for all batches on a device - Saves a bit of memory
#CUFFT_PLAN_INP 		SINGLE

########################### Powers #############################

# How to calculate powers in the standard search
# STD_POWERS:
#	CB			# Use CUFFT callbacks to calculate powers. Almost always a good option!
#	SS			# Do the power calculations in the Sum and search step
# D	AUTO			# Let the application decide
STD_POWERS 		AUTO


# How to calculate powers in in-mem search
# IN_MEM_POWERS:
#	CB			# Use a CUFFT callback with the in-mem iFFT's to calculate powers - write strait to in-mem plane - In my testing this is very slow
#	MEM_CPY			# Use a CUFFT callback with the in-mem iFFT's to calculate powers - write to separate powers plane, and the used asynch memory copy to move powers to in-mem plane. Uses more memory but fast
#	KERNEL			# Use a separate kernel to calculate powers and write to in-mem plane - slower but uses slightly less memory
# D	AUTO			# Let the application decide
IN_MEM_POWERS		AUTO


# If performing a in-mem GPU search store powers in half precision (allows doing twice as large in-mem searches)
# POWER_PRECISION:
#	HALF			# Force half precision powers - much faster a good very good option! (requires CUDA 7.5 or greater)
#	SINGLE			# Force single precision powers
#	DOUBLE			# Not yet implemented - Not sure if this is really necessary
# D	AUTO			# Let the application decide - Will usually result in half
POWER_PRECISION		AUTO


######################## Sum & Search ##########################

# The type of Sum & Search to perform
# SS_KER:
#	CPU			# [Deprecated]	It takes much longer to copy the full powers plane to the device than it doses to search it
#	00			# DEBUG This is just a dummy kernel and will give incorrect values! (it is close to optimal calculations)
#	10			# This is the standard sum and search kernel
#	IM or INMEM		# Do a in-memory sum and search (if possible always try this!)
# D	AA			# Automatically chose, this will do a in-mem search if possible
SS_KER			AA


# Count initial candidates in Sum & Search kernel
# SS_COUNT:
#	0			# Do not count candidates
# D	1			# Count candidates in the kernel allows opting out of some CPU work
SS_COUNT		1


#FLAG_SAS_TEX   		# [Deprecated]	Use texture memory in the sum and search kernel
#FLAG_TEX_INTERP		# [Deprecated]	Use texture memory & interpolation in the multiplication kernel


# The number of horizontal "slices" to break the Sum & Search kernel into
# SS_SLICES:
#	int			# A number generally less than 7 and odd are "better"
# D	0			# Let the application decide
SS_SLICES		0


# The number of values to buffer in the Sum & Search kernel (this increases register use)
# SS_CHUNK:
#	int			# A number <= 12
# D	0			# Let the application decide
SS_CHUNK		0


SS_COLUMN		0


# The step size of the in-mem search, this can be any value good choices are powers of two: 2048 or 4096 or 8192 or 16384 or 32768 or 65536 or 131072
# SS_INMEM_SZ:
# D	0       		# Let the application decide
#	2048
#	4096
#	8192
#	16384
#	32768
#	65536
#	131072
#	262144
#	524288
SS_INMEM_SZ 		0



################### Process initial candidates #################

# Use separate CPU threads to process results
# CAND_PROCESS:
# D	THREAD			# Do per step initial candidate sigma calculations in a separate CPU thread - this is generally a good idea
#	SEQ			# Force CPU sequential for sigma calculations - some times the CPU just inst fast enough, so not really a good idea =/   sorry CPU
#CAND_PROCESS		SEQ


# Memory for CPU threads processing results
# CAND_MEM:
# D	RING			# Use the ring buffer (this may require upping the number of elements in the ring buffer)
#	PRE			# Allocate temporary memory for each thread processing results - The allocation can slow things down but if there is lots of RFI this can allow the thread to run longer
#CAND_MEM		PRE


#FLAG_STORE_ALL 		# [Not yet implemented]	Don't fiddle with this this is for future use
#FLAG_STORE_EXP 		# [Not yet implemented]	Don't fiddle with this this is for future use


# How to store initial candidates
# CAND_STORAGE:
# D	ARR     		# Use an array		(Fast access, but requires more CPU memory)
#	LST     		# Use a linked list	(Slower but requires less CPU memory)
#	QUAD    		# Use a quad tree	(Better all round - But not yet properly implemented)
CAND_STORAGE		ARR

# The resolution of the canidate array
# This is only used if the CAND_STORAGE is set to ARR
# This can generally be a smaller number say 0.5 or 0.25 a smaller number will use less host memory to store initial candidates
# If two initial candidates with similar values are found the one with the higher sigma will over writ the other
#
# ARR_RES: (A float value)
#	0.25:			# This will generate a canidate array with 1 bin per 4 input FT bins
# D	0.5:			# This will generate a canidate array with 1 bin per 2 input FT bins
#	1:			# This will generate a canidate array with 1 bin per 1 input FT bin - You shouldn't really have to go lager than this
#	2:			# This will generate a canidate array with 2 bin per 1 input FT bin ( this is generally the resolution the search is done at see: R_RESOLUTION )
ARR_RES			0.5

######################### Optimisation ###########################

# OPT_METHOUD
# D	PLANE			#
#	SWARM			#
#	NM			#
OPT_METHOUD		PLANE

# OPT_Z_RATIO
#	float     		# This is the ratio between bin sizes in optimisation it is Z/R
# D	4			# This is the default in accelsearch
OPT_Z_RATIO		4

# OPT_R_RES [Deprecated]
#	float     		#
# D	16			#
OPT_R_RES		16

# How to normalise the powers of the optimised candidates
# OPT_NORM
# 	NONE  			# Not recommended
# D	MEDIAN1D  		# Use 1D median power for normalisation
# 	MEDIAN2D  		# Use 2D median power for normalisation
#	LOCAVE  		# Use Local 3D power average for normalisation - This is the original PRESTO method and its actually 2D
OPT_NORM		MEDIAN


# FLAG_OPT_BEST:		# Report the harmonic with the highest sigma value rather than the number of harmonic found during the initial search, this generally wont hurt
FLAG_OPT_BEST		0


# This is the minimum number of harmonics that will be summed when localising the initial candidate
# OPT_MIN_LOC_HARMS:
# D	1			# This means the optimisation of the position will be done using the number of harmonics the initial candidate was found with
OPT_MIN_LOC_HARMS	1

#
# OPT_MIN_REP_HARMS
#	int     		# If this number is larger than the number of harmonics the initial candidate was found with, optimisation will check harmonics up to this number. use with "OPT_BEST" to report this value.
#	24			# This is my preferred value this will sum up to 24 harmonics
# D	1			# This means the optimisation of the candidate will check up to the number of harmonics the initial candidate was found with
OPT_MIN_REP_HARMS	1


# Do a final Nelder Mead refinement on the location, generally a good idea
OPT_NELDER_MEAD_REFINE	1


# Use separate CPU threads to process results
# OPT_PROCESS:
# D	THREAD			# Do CPU component of optimisation in a separate CPU thread - This is generally a good idea
#	SEQ			# Do CPU component of optimisation in a the same CPU thread - Not a good idea
#OPT_PROCESS		SEQ

# TODO: Write this description
#OPT_BLK_DIVISOR

#### The rest are optimisation plane parameters ####

# Optimisation location finding step down
# Each successive iteration of the incremental planes will be X times smaller
# D	10			# Each plane reduces the template size by one order of magnitude  ( /10 )
optPlnScale		10

# Use dynamic half-width in the optimisation planes, this is on by default
FLAG_OPT_DYN_HW		1


# The Numbers below dictate how may points and thus the size of the incremental planes used to refine the location of the maximum f-f value
# Lager numbers will take longer to run but have a finer resolution
optPlnDim 1 128			# The number of elements in the 1st optimisation plane
optPlnDim 2 32   		# The number of elements in the 2nd optimisation plane
optPlnDim 3 16  		# The number of elements in the 3rd optimisation plane
optPlnDim 4 16			# The number of elements in the 4th optimisation plane
optPlnDim 5 0   		# The number of elements in the 5th optimisation plane - These may be double depending on the size of optPlnSiz and optPlnScale
optPlnDim 6 0   		# The number of elements in the 6th optimisation plane - These will probably be double depending on the size of optPlnSiz and optPlnScale
optPlnDim 7 0   		# The number of elements in the 7th optimisation plane (this is a double precision plane)


# The Numbers below dictate the size, in bins, of the first incremental plane used to refine the location of the maximum f-fdot value, for each number of harmonics
# Lager numbers will "explore" the f-fdot plane faster but will reduce resolution
optPlnSiz 1  16
optPlnSiz 2  14
optPlnSiz 4  12
optPlnSiz 8  10
optPlnSiz 16 8


######################### Debug ###########################

# The level of debug messages to print 0 -> non  more with increasing number
# DBG_LEV:
# D	0       		# None
#	1       		# Stage info	- Initialisation - Candidate generation - Candidate optimisation
#	2       		# Component	- Naming the components
#	3       		# Component info- Details on the components, Input FT - Multiplication - Power calculation - sum & search - etc....
#	4       		# Detail	- Info on what task is being done - ie, zero memory, kernel calls etc.
#	5       		# Debug		- Full debug information - CUDA Events etc.
#	6       		# Super		- Details on the values of actual variables
#	7			# Excessive!
DBG_LEV			0

#FLAG_DPG_UNOPT  		# [ Debug ]	Use saved initial search values
#FLAG_DBG_SKIP_OPT		# [ Debug ]	Don't do optimisation
#FLAG_DPG_PRNT_CAND		# [ Debug ]     Print CSV of candidates at various stages
#FLAG_DPG_PLT_POWERS		# [ Debug ]	Plot powers should only be done using FLAG_DBG_SYNCH
#FLAG_DPG_PLT_OPT		# [ Debug ]	Plot optimisation planes
#FLAG_DBG_TEST		0

#FLAG_DBG_SYNCH  		# [ Debug ]	Perform a synchronous search
#FLAG_DBG_PROFILING		# [ Debug ]	Perform advanced profiling and timing the search






