# 	This file contains the settings to control how the GPU acceleration search is carried out
#	#'s Comment out lines, blank lines are ignored
#	Uncomment settings as you desire
#	Generally if two flags are on one after the other in this file they are a either or option, the last uncommitted one will be used
#	
#	If you have any questions pleas e-mail Chris Laidler  chris.laidler+presto@gmail.com


######## Memory #########

# Interleaving
#IL_ROW				# Interleave steps row by row
#IL_PLN				# Interleave steps row by plane

######### Kernel #########

#FLAG_KER_STD			# Standard low accuracy method of choosing the half-width
FLAG_KER_HIGH			# Choose larger half-width for higher accuracy of value of z close to 0

#FLAG_KER_MAX			# Choose largest possible response function width

FLAG_CENTER			# Centre the kernels

########## Input #########

# Normalise input in the CPU or the GPU
NORM_CPU			# Do the input Normalisation on the CPU
#NORM_GPU			# Do the input Normalisation on the GPU

# FFT input in the CPU or the GPU
FFT_CPU  			# Do the input FFT's on the CPU
#FFT_GPU  			# Do the input FFT's on the GPU

# cuMedianBuffSz		# This is the size of buffers to use in the median selection algorithm used by the CUDA input normalisation kernel this should be one of: 128, 256, 512, 1024, 2048, 4096, 8192

######## Convolve ########

# Which type of multiplication to do. Note MUL_00 is just a dummy kernel and will give incorrect values!
# In my testing MUL_CB is very slow, like 7 times slower (FFT only)!
# MUL_00  MUL_10  MUL_21  MUL_22  MUL_23  MUL_30  MUL_CB  MUL_AA
MUL_23

#FLAG_TEX_MUL			# [Deprecated]	Use texture memory in the multiplication kernel

MUL_SLICES	5		# The number of horizontal "slices" to break the multiplication kernel into

MUL_CHUNK	9		# The number of values to buffer in the multiplication kernel (this increases register use)

# How to do convolution
#FLAG_SEP			# Do the multiplication and iFFT "separately"	ie all multiplications followed by all iFFT's
#FLAG_CONV			# Do the multiplication and iFFT "together"	ie multiply and iFFT each stack one after the other

# Which order to call stacks
#FLAG_STK_DOWN			# larges to smallest
#FLAG_STK_UP			# smallest to larges

######### FFT ############

FLAG_CUFFT_CB_POW		# Almost always a good option!
#FLAG_CUFFT_CB_INMEM		# In my testing this is very slow
#FLAG_NO_CB			# Force using no CUFFT callbacks

#FLAG_FFT_SEPERATE		# Use separate CUFFT plans for each batch, alternative is to use one plan for all batches on a device

######## Return ##########

# FLAG_RET_ARR			# [Deprecated]
#FLAG_RET_PLN			# [Deprecated]

######## Search ##########

# If performing a in-mem GPU search store powers in half precision (allows doing twice as large in-mem searches)
FLAG_SINGLE			# Force single precision powers
#FLAG_HALF			# Force half precision powers (requires CUDA 7.5 or greater)

#FLAG_SAS_TEX			# [Deprecated]	Use texture memory in the sum and search kernel
#FLAG_TEX_INTERP		# [Deprecated]	Use texture memory & interpolation in the multiplication kernel

#SIG_GPU			# 		Now the default
#SIG_CPU			# [Deprecated]	Do the candidate sigma calculations on the GPU

# Use separate CPU threads to process results
#FLAG_THREAD			# (default)	Force CPU threading for sigma calculations
FLAG_SEQ			# 		Force CPU sequential for sigma calculations

# The type of Sum & Search to perform
#  SS_CPU  SS_00  SS_10  SS_INMEM  SS_AA
SS_10

SS_SLICES	5		# The number of horizontal "slices" to break the Sum & Search kernel into

SS_CHUNK	9		# The number of values to buffer in the Sum & Search kernel (this increases register use)

SS_INMEM_SZ	32768		# The step size of the in-mem search, this can be any value good choices are powers of two: 2048 or 4096 or 8192 or 16384 or 32768

###### Candidates ########

#FLAG_STORE_ALL			# [Not yet implemented]		Don't fiddle with this this is for future use
#FLAG_STORE_EXP			# [Not yet implemented]		Don't fiddle with this this is for future use

# How to store candidates
CU_CAND_ARR			# Use an array 			(Fast access, but requires more CPU memory)
#CU_CAND_LST			# Use a linked list		(Slower but requires less CPU memory)
#CU_CAND_QUAD			# Use a quad tree		(Better all round - But not yet properly implemented)


###### Optimisation ########

# The Numbers below dictate how may points and thus the size of the incremental planes used to refine the location of the maximum f-f value
# Lager numbers will take longer to run but have a finer resolution
optpln01 40			# The number of elements in the 1st optimisation plane
optpln02 30			# The number of elements in the 2nd optimisation plane
optpln03 20			# The number of elements in the 3rd optimisation plane
optpln04 10			# The number of elements in the 4th optimisation plane
optpln05 0			# The number of elements in the 5th optimisation plane
optpln06 0			# The number of elements in the 6th optimisation plane (this is a double preseason plane)

# The Numbers below dictate the size in bins of the incremental planes used to refine the location of the maximum f-fdot value
# Lager numbers will explore the f-fdot plane faster but will reduce resolution
#optSz01 4
#optSz02 4
#optSz04 4
#optSz08 4
#optSz16 4


###### Debug ########

#PLT_OPT			# [Debug]		
#UNOPT				# [Debug]	
#SKP_OPT    			# [Debug] Don't do optimisation

DBG_LEV 0			# [Debug]	The level of debug messages to print 0 -> non  more with increasing number
#	0			# None [default]
#	1			# Info
#	2			# Debug 1
#	3			# Debug 2
#	4			# Debug 3
#	5			# Debug 4

#FLAG_DBG_SYNCH			# [ Debug ] Perform a synchronous search
#FLAG_DBG_TIMING   		# [ Debug ] Perform advanced timing the search
FLAG_DPG_PRNT_CAND		# [ Debug ] Print CSV of candidates at various stages



